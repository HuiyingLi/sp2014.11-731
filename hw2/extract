#!/usr/bin/env python
import math
import match
import pdb
import argparse
import json
import os, sys, math
import string_kernel as sk
import re
import gen_lmstat as lm
import numpy as np
#kernel="eq"
#kernel='ed' #edit distance
#kernel='lcs'
kernel='pre6'
alpha=5 #metoer alpha(precision portion out of 10)
beta=4.5 #bleu beta(precision portion out of 10)
stagedecay=0.05
smooth=0
#style=set(['bleu'])
style=set(['bleu','me'])
puct=[',','.','?',':',"'",'"',"(",")"]
#split string into words and normalize
def string2words(s):
    s=s.lower()
    l=re.compile('\.|,|\s|\(|\)|\'|\?|:|\"').split(s)
    res=[]
    for w in l:
        if len(w)>0:
            res.append(w)
    return res
    
#takes in a list of words and make a dict where key is the word
#and value is the frequency:
def freq_dict(words, n):
    d={}
    if n==1:
        for w in words:
            if w not in d:
                d[w]=1.0
            else:
                d[w]=d[w]+1
    elif n==2:
        for i in range(len(words)-1):
            bi=tuple([words[i],words[i+1]])
            if bi not in d:
                d[bi]=1.0
            else:
                d[bi]=d[bi]+1
    elif n==3:
        for i in range(len(words)-2):
            tri=tuple([words[i],words[i+1],words[i+2]])
            if tri not in d:
                d[tri]=1.0
            else:
                d[tri]=d[tri]+1
    return d

def string_eql(h,r):
    if kernel=='eq':
        if h==r:
            return True
    if kernel=='ed':
        if sk.levenshtein(h,r)<2:
            return True

    if kernel=='lcs':
        cs=sk.lcs(h,r)
        if len(cs)*1.0/min(len(h),len(r)) >=0.75:
            return True
    if kernel.startswith('pre'):
        n=int(kernel[-1])
        if len(h)>=n:
            h=h[:n]
        if len(r)>=n:
            r=r[:n]
        if h==r:
            return True
    return False

#the arguments are list of strings whose lengths equal 2 or 3
def ngram_eql(h, r):
    n=len(h) 
    sum=0
    for i in range(n):
        if string_eql(h[i], r[i]):
            sum+=1
    if sum==n:
        return True
    return False

##takes in 2 lists of strings, map them according to Meteor paper
def map(hwords,rwords):
    al=np.zeros(len(hwords))-np.ones(len(hwords))#array of all -1
    taken=np.ones(len(rwords))
    for i in range(len(hwords)):
        h=hwords[i]
        for j in range(len(rwords)):
            r=rwords[j]
            if taken[j]==1:
                if string_eql(h,r):
                    al[i]=j
                    taken[j]=0
    return al
def extract_features(hyp, ref):
    featdict={}
#    pdb.set_trace()
    hwords = hyp.lower().split()
    rwords = ref.lower().split()
######################## LM features #############################
    if 'lm' in style:
        featdict['unilm']=lm.calc_sentlm(hwords,1)*0.1
        featdict['bilm']=lm.calc_sentlm(hwords,2)*0.1
        featdict['trilm']=lm.calc_sentlm(hwords,3)*0.1
######################## meteor score ############################
    if 'me' in style:
        match1=match.stage1(rwords, hwords)
        sum=0
        misp=0
        for i in range(len(match1)):
            m=match1[i]
            if m!=-1:
                sum+=1
                misp-=math.fabs(i*1.0/len(match1)-m*1.0/len(rwords))
            else:
                misp-=1.0
        match2=match.stage2(rwords,hwords,match1)
        for m in match2:
            if m!=-1:
                sum+=stagedecay
        prec=sum*1.0/len(hwords)
        rec=sum*1.0/len(rwords)
        if prec>0 and rec>0:
            fmean=10*prec*rec/(alpha*prec+rec)
        else:
            fmean=0
        #featdict['mprec']=prec
        #featdict['mrec']=rec
        #featdict['mfmean']=fmean
        featdict['misposition']=misp/len(hwords) 
        ##gather high order ngram
        i=0
        '''
        nchunk=0
        while(i<len(hwords)-1):
            i+=1            
            if align[i]!=-1:
                if align[i]!=align[i-1]-1:
                    nchunk+=1
        if sum>0:
            penalty=nchunk*1.0/sum
            penalty=0.5*penalty*penalty*penalty
        else:
            penalty=0.5
#        featdict['mpenalty']=penalty
'''
#    hwords=string2words(hyp)
#    rwords=string2words(ref)
   # refset = set(rwords)
   # precision = sum(1.0 for word in hwords if word in refset) / len(hwords)
    if 'bleu' in style:
#####################unigram precision recall #####################
        refd=freq_dict(rwords,1)
        hd=freq_dict(hwords,1)
        #modified unigram
        sum=0
        for h in hd:
            for r in refd:
                if refd[r]>0:
                    if string_eql(h,r):
                        if hd[h]>=refd[r]:
                            sum+=refd[r]
                            refd[r]=0
                        else:
                            refd[r]-=hd[h]
                            sum+=hd[h]
                        break
        precision=sum*1.0/len(hwords)
        recall=sum*1.0/len(rwords)
        featdict['prec']=precision+smooth
        featdict['recall']=recall+smooth
        if precision>0 and recall>0:
            featdict['fmean']=10*precision*recall/((10-beta)*recall+beta*precision)+smooth
        else:
            featdict['fmean']=0+smooth
####################bigram precision recall ######################
        refbid=freq_dict(rwords,2)
        hbid=freq_dict(hwords,2)
        sum=0
        for h in hbid:
            for r in refbid:
                if ngram_eql(h,r):
                    if hbid[h]>=refbid[r]:
                        sum+=refbid[r]
                        refbid[r]=0
                    else:
                        refbid[r]-=hbid[h]
                        sum+=hbid[h]
        if len(hwords)>1 and len(rwords)>1:
            biprecision=sum*1.0/(len(hwords)-1)
            birecall=sum*1.0/(len(rwords)-1)
        else:
            biprecision=0
            birecall=0
        featdict['biprec']=biprecision+smooth
        featdict['birecall']=birecall+smooth
###################trigram precision recall ######################
        reftrid=freq_dict(rwords,3)
        htrid=freq_dict(hwords,3)
        sum=9
        for h in htrid:
            for r in reftrid:
                if ngram_eql(h,r):
                    sum+=reftrid[r]
                    reftrid[r]=0
                else:
                    reftrid[r]-=htrid[h]
                    sum+=htrid[h]
        if len(hwords)>2 and len(rwords)>2:
            triprecision=sum*1.0/(len(hwords)-2)
            trirecall=sum*1.0/(len(rwords)-2)
        else:
            triprecision=0
            trirecall=0
#    featdict['triprec']=triprecision+smooth
#    featdict['trirecall']=trirecall+smooth
    return featdict

argparser = argparse.ArgumentParser(prog='extract')
argparser.add_argument('-x', '--pairs', dest='pairs', default='data/en-cs.pairs', help='Reference-Hypothesis pairs')

args = argparser.parse_args()

lc = 0
sys.stderr.write('Extracting features for (ref,hyp) pairs from %s.\n' % args.pairs)
# loop over all (ref,hyp) pairs in the input file and extract evaluation features
for ref_hyp in open(args.pairs):
    lc += 1
    if lc%1000==0:
        sys.stderr.write("processed "+str(lc)+"\n")
    ref, hyp = ref_hyp.rstrip().split(' ||| ')
    fmap = extract_features(hyp, ref)
    print json.dumps(fmap)   # print evaluation feature map

